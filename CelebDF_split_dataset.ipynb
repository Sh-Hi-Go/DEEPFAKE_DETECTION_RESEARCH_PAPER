{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5EWTuMuR3O2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your original dataset\n",
        "original_dataset_path = '/content/drive/MyDrive/celebDF_processed/dataset'\n",
        "\n",
        "# Create the destination directory for the split dataset\n",
        "split_dataset_path = '/content/drive/MyDrive/celebDF_processed_split'\n",
        "os.makedirs(split_dataset_path, exist_ok=True)  # Create if it doesn't exist"
      ],
      "metadata": {
        "id": "sGTjr6QVSFiW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the classes (real and fake)\n",
        "for class_name in os.listdir(original_dataset_path):\n",
        "    class_path = os.path.join(original_dataset_path, class_name)\n",
        "\n",
        "    # Create subdirectories for train, test, and validation in the split dataset\n",
        "    train_dir = os.path.join(split_dataset_path, 'Train', class_name)\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    test_dir = os.path.join(split_dataset_path, 'Test', class_name)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    val_dir = os.path.join(split_dataset_path, 'val', class_name)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    # Get a list of image filenames in the class directory\n",
        "    image_filenames = os.listdir(class_path)\n",
        "\n",
        "    # Shuffle the filenames to ensure a random split\n",
        "    random.shuffle(image_filenames)\n",
        "\n",
        "    # Split the filenames into 80:10:10 ratios for train, test, and validation\n",
        "    train_filenames = image_filenames[:int(0.8 * len(image_filenames))]\n",
        "    test_filenames = image_filenames[int(0.8 * len(image_filenames)):int(0.9 * len(image_filenames))]\n",
        "    val_filenames = image_filenames[int(0.9 * len(image_filenames)):]\n",
        "\n",
        "    # Move the images to their respective directories\n",
        "    for filename in train_filenames:\n",
        "        src = os.path.join(class_path, filename)\n",
        "        dst = os.path.join(train_dir, filename)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "    for filename in test_filenames:\n",
        "        src = os.path.join(class_path, filename)\n",
        "        dst = os.path.join(test_dir, filename)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "    for filename in val_filenames:\n",
        "        src = os.path.join(class_path, filename)\n",
        "        dst = os.path.join(val_dir, filename)\n",
        "        shutil.copy2(src, dst)"
      ],
      "metadata": {
        "id": "ZJUtTAzASJ1v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qhsSvu4Tj7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}